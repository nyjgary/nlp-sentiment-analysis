{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import string\n",
    "import random\n",
    "from os import listdir \n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Process Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper methods to load reviews from directories \n",
    "\n",
    "def load_single_review(fdir, fname): \n",
    "    \"\"\" Takes as input file directory and file name of a single review, returns review as string \"\"\"\n",
    "    fpath = fdir + '/' + fname \n",
    "    with open(fpath, 'r') as f: \n",
    "        review = f.read()\n",
    "        return review \n",
    "    \n",
    "def load_dir_reviews(fdir): \n",
    "    \"\"\" Takes as input file directory where reviews are stored, returns them as a list of review strings \"\"\"\n",
    "    fnames = [f for f in listdir(fdir)]\n",
    "    reviews = [load_single_review(fdir, fname) for fname in fnames]\n",
    "    return reviews\n",
    "\n",
    "def combine_data(neg_reviews, pos_reviews): \n",
    "    \"\"\" Combines lists of negative and positive reviews, returns a combined dataset comprising reviews and labels \"\"\"\n",
    "    neg_with_labels = [(review, 0) for review in neg_reviews] \n",
    "    pos_with_labels = [(review, 1) for review in pos_reviews]\n",
    "    combined = neg_with_labels + pos_with_labels\n",
    "    combined = random.sample(combined, len(combined))\n",
    "    reviews = [comb[0] for comb in combined]\n",
    "    labels = [comb[1] for comb in combined]\n",
    "    return reviews, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reviews into lists \n",
    "train_val_neg = load_dir_reviews('aclImdb/train/neg')\n",
    "train_val_pos = load_dir_reviews('aclImdb/train/pos')\n",
    "test_neg = load_dir_reviews('aclImdb/test/neg')\n",
    "test_pos = load_dir_reviews('aclImdb/test/pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split train into train vs. validation sets \n",
    "train_split = int(20000 / 2) \n",
    "train_neg = train_val_neg[:train_split]\n",
    "train_pos = train_val_pos[:train_split]\n",
    "val_neg = train_val_neg[train_split:]\n",
    "val_pos = train_val_pos[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Validation dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "# combine pos and neg reviews to get unified datasets \n",
    "train_data, train_labels = combine_data(train_neg, train_pos)\n",
    "val_data, val_labels = combine_data(val_neg, val_pos)\n",
    "test_data, test_labels = combine_data(test_neg, test_pos)\n",
    "print (\"Train dataset size is {}\".format(len(train_data)))\n",
    "print (\"Validation dataset size is {}\".format(len(val_data)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
